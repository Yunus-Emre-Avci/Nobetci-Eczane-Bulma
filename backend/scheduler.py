"""
Otomatik Scraping ZamanlayÄ±cÄ±
Her gÃ¼n saat 09:00'da (TR Ä°stanbul saati) scraping iÅŸlemini otomatik olarak Ã§alÄ±ÅŸtÄ±rÄ±r.
"""
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.cron import CronTrigger
from pytz import timezone
from datetime import datetime
import asyncio
from database import async_session
from scraper import scrape_and_save_pharmacies
import logging

# Logging ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# TÃ¼rkiye saat dilimi
TR_TZ = timezone('Europe/Istanbul')

# Scheduler instance
scheduler = AsyncIOScheduler(timezone=TR_TZ)

async def scheduled_scraping_task():
    """
    ZamanlanmÄ±ÅŸ scraping gÃ¶revi.
    Her gÃ¼n 09:00'da otomatik olarak Ã§alÄ±ÅŸÄ±r.
    """
    logger.info(f"ğŸ•’ Otomatik scraping baÅŸlatÄ±ldÄ± - {datetime.now(TR_TZ).strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        # Async session oluÅŸtur
        async with async_session() as db:
            # Scraping iÅŸlemini Ã§alÄ±ÅŸtÄ±r (generator olduÄŸu iÃ§in consume etmemiz gerekiyor)
            async for log_message in scrape_and_save_pharmacies(db):
                # Log mesajlarÄ±nÄ± yazdÄ±r
                if log_message.startswith("PROGRESS"):
                    parts = log_message.split("|")
                    if len(parts) >= 3:
                        logger.info(f"ğŸ“Š Ä°lerleme: %{parts[1]} - {parts[2].strip()}")
                else:
                    logger.info(f"ğŸ“ {log_message.strip()}")
        
        logger.info("âœ… Otomatik scraping baÅŸarÄ±yla tamamlandÄ±!")
        
    except Exception as e:
        logger.error(f"âŒ Otomatik scraping hatasÄ±: {e}")

def start_scheduler():
    """
    Scheduler'Ä± baÅŸlatÄ±r ve zamanlanmÄ±ÅŸ gÃ¶revi ekler.
    Her gÃ¼n saat 09:00'da Ã§alÄ±ÅŸacak ÅŸekilde ayarlanÄ±r.
    """
    # Cron trigger: Her gÃ¼n saat 09:00'da Ã§alÄ±ÅŸ
    trigger = CronTrigger(
        hour=9,
        minute=0,
        timezone=TR_TZ
    )
    
    # GÃ¶revi scheduler'a ekle
    scheduler.add_job(
        scheduled_scraping_task,
        trigger=trigger,
        id='daily_pharmacy_scraping',
        name='GÃ¼nlÃ¼k Eczane Scraping',
        replace_existing=True
    )
    
    # Scheduler'Ä± baÅŸlat
    scheduler.start()
    
    logger.info("ğŸš€ Scheduler baÅŸlatÄ±ldÄ±!")
    logger.info(f"â° Scraping her gÃ¼n saat 09:00'da (TR Ä°stanbul saati) otomatik olarak Ã§alÄ±ÅŸacak")
    
    # Bir sonraki Ã§alÄ±ÅŸma zamanÄ±nÄ± gÃ¶ster
    next_run = scheduler.get_job('daily_pharmacy_scraping').next_run_time
    logger.info(f"ğŸ“… Bir sonraki Ã§alÄ±ÅŸma zamanÄ±: {next_run.strftime('%Y-%m-%d %H:%M:%S %Z')}")

def stop_scheduler():
    """
    Scheduler'Ä± durdurur.
    """
    scheduler.shutdown()
    logger.info("ğŸ›‘ Scheduler durduruldu!")

# Manuel test iÃ§in endpoint
async def run_scraping_now():
    """
    Scraping'i hemen Ã§alÄ±ÅŸtÄ±rmak iÃ§in kullanÄ±labilir (test amaÃ§lÄ±).
    """
    logger.info("ğŸ”§ Manuel scraping baÅŸlatÄ±ldÄ±...")
    await scheduled_scraping_task()
